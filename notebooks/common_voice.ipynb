{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.audio_utils import get_total_audio_duration,get_audio_info\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from utils.file_utils import save_json\n",
    "from utils.transcription_utils import clean_and_verify_transcript_hi,get_transcription_info,get_stats,get_total_stats\n",
    "from collections import Counter\n",
    "from utils.conversions import sec_to_time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path=Path(\"/media/dataset-harddisk/munikumar/utils/audio_utils/data/common_voice/nuktas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir=Path(\"/media/dataset-harddisk/munikumar/hindi_dataset/common_voice/cv-corpus-13.0-2023-03-09/hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transcription(transcription_path):\n",
    "    with open(transcription_path, \"r\", encoding=\"utf-8\") as fp:\n",
    "        reader=csv.reader(fp,delimiter='\\t')\n",
    "        next(reader)\n",
    "        transcription_data = {\n",
    "            transcription[1]:transcription[2]\n",
    "            for transcription in reader\n",
    "        }\n",
    "    return transcription_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting audio info about : nuktas - test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 17/2947 [00:01<03:11, 15.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2947/2947 [02:33<00:00, 19.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Loss of audio data without transcription normalization:\n",
      "**************************************************\n",
      "Total duration : 4:4:19\n",
      "Loss duration : 3:14:12\n",
      "Remaining duration : 0:50:6\n",
      "Drop by percentage: 79.49\n",
      "\n",
      "Total audio files : 2947\n",
      "Files that would be drop: 2396\n",
      "Remaining audio files : 551\n",
      "Drop by percentage: 81.30\n",
      "**************************************************\n",
      "Non hindi tokes : ['!', '\"', '&', \"'\", ',', '-', '.', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'I', 'J', 'K', 'L', 'M', 'O', 'P', 'R', 'S', 'T', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '।', '–', '‘', '’']\n"
     ]
    }
   ],
   "source": [
    "test_transcription_data=load_transcription(dataset_dir/\"test.tsv\")\n",
    "get_transcription_info(test_transcription_data,dataset_dir/\"clips\",save_path,\"test\")\n",
    "get_stats(save_path/\"test_non_hindi_transcripts.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data\n",
    "**************************************************\n",
    "**Loss of audio data without transcription normalization:**\n",
    "**************************************************\n",
    "Total duration : 4:4:19  \n",
    "Loss duration : 3:14:59  \n",
    "Remaining duration : 0:49:19  \n",
    "Drop by percentage: 79.81  \n",
    "\n",
    "Total audio files : 2947  \n",
    "Files that would be drop: 2404  \n",
    "Remaining audio files : 543  \n",
    "Drop by percentage: 81.57  \n",
    "**************************************************\n",
    "Non hindi tokes : ['!', '\"', '&', \"'\", ',', '-', '.', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'I', 'J', 'K', 'L', 'M', 'O', 'P', 'R', 'S', 'T', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', 'ख़', 'ज़', 'ड़', 'ढ़', '।', '–', '‘', '’']\n",
    "\n",
    "**************************************************\n",
    "**Loss of audio data After Decomposing Nuktas:**\n",
    "**************************************************\n",
    "Total duration : 4:4:19  \n",
    "Loss duration : 3:14:12  \n",
    "Remaining duration : 0:50:6  \n",
    "Drop by percentage: 79.49  \n",
    "\n",
    "Total audio files : 2947  \n",
    "Files that would be drop: 2396  \n",
    "Remaining audio files : 551  \n",
    "Drop by percentage: 81.30  \n",
    "**************************************************\n",
    "Non hindi tokes : ['!', '\"', '&', \"'\", ',', '-', '.', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'I', 'J', 'K', 'L', 'M', 'O', 'P', 'R', 'S', 'T', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '।', '–', '‘', '’']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting audio info about : nuktas - dev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2281 [00:00<01:54, 19.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2281/2281 [01:59<00:00, 19.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Loss of audio data without transcription normalization:\n",
      "**************************************************\n",
      "Total duration : 2:56:15\n",
      "Loss duration : 2:19:10\n",
      "Remaining duration : 0:37:4\n",
      "Drop by percentage: 78.96\n",
      "\n",
      "Total audio files : 2281\n",
      "Files that would be drop: 1849\n",
      "Remaining audio files : 432\n",
      "Drop by percentage: 81.06\n",
      "**************************************************\n",
      "Non hindi tokes : ['!', '\"', \"'\", ',', '-', '.', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '।', '‘', '’']\n"
     ]
    }
   ],
   "source": [
    "dev_transcription_data=load_transcription(dataset_dir/\"dev.tsv\")\n",
    "get_transcription_info(dev_transcription_data,dataset_dir/\"clips\",save_path,\"dev\")\n",
    "get_stats(save_path/\"dev_non_hindi_transcripts.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev Dataset\n",
    "**************************************************\n",
    "Loss of audio data without transcription normalization:\n",
    "**************************************************\n",
    "Total duration : 2:56:15  \n",
    "Loss duration : 2:19:57  \n",
    "Remaining duration : 0:36:17  \n",
    "Drop by percentage: 79.41  \n",
    "\n",
    "Total audio files : 2281  \n",
    "Files that would be drop: 1858  \n",
    "Remaining audio files : 423  \n",
    "Drop by percentage: 81.46  \n",
    "**************************************************\n",
    "Non hindi tokes : ['!', '\"', \"'\", ',', '-', '.', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', 'ग़', 'ज़', 'ड़', 'ढ़', '।', '‘',]\n",
    "\n",
    "**************************************************\n",
    "**Loss of audio data After Decomposing Nuktas:**\n",
    "**************************************************\n",
    "Total duration : 2:56:15  \n",
    "Loss duration : 2:19:10  \n",
    "Remaining duration : 0:37:4  \n",
    "Drop by percentage: 78.96  \n",
    "\n",
    "Total audio files : 2281  \n",
    "Files that would be drop: 1849  \n",
    "Remaining audio files : 432  \n",
    "Drop by percentage: 81.06  \n",
    "**************************************************\n",
    "Non hindi tokes : ['!', '\"', \"'\", ',', '-', '.', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '।', '‘', '’']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting audio info about : nuktas - train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/4479 [00:00<03:38, 20.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4479/4479 [03:46<00:00, 19.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Loss of audio data without transcription normalization:\n",
      "**************************************************\n",
      "Total duration : 5:17:19\n",
      "Loss duration : 3:58:50\n",
      "Remaining duration : 1:18:29\n",
      "Drop by percentage: 75.26\n",
      "\n",
      "Total audio files : 4479\n",
      "Files that would be drop: 3392\n",
      "Remaining audio files : 1087\n",
      "Drop by percentage: 75.73\n",
      "**************************************************\n",
      "Non hindi tokes : ['!', '\"', '&', \"'\", ',', '-', '.', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '।', '‘', '’', '“', '”']\n"
     ]
    }
   ],
   "source": [
    "train_transcription_data=load_transcription(dataset_dir/\"train.tsv\")\n",
    "get_transcription_info(train_transcription_data,dataset_dir/\"clips\",save_path,\"train\")\n",
    "get_stats(save_path/\"train_non_hindi_transcripts.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Dataset\n",
    "**************************************************\n",
    "Loss of audio data without transcription normalization:\n",
    "**************************************************\n",
    "Total duration : 5:17:19  \n",
    "Loss duration : 4:0:41  \n",
    "Remaining duration : 1:16:38  \n",
    "Drop by percentage: 75.85  \n",
    "\n",
    "Total audio files : 4479  \n",
    "Files that would be drop: 3418  \n",
    "Remaining audio files : 1061  \n",
    "Drop by percentage: 76.31  \n",
    "**************************************************\n",
    "Non hindi tokes : ['!', '\"', '&', \"'\", ',', '-', '.', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', 'क़', 'ज़', 'ड़', 'ढ़', 'फ़', '।', '‘', '’', '“', '”']\n",
    "\n",
    "**************************************************\n",
    "**Loss of audio data After Decomposing Nuktas:**\n",
    "**************************************************\n",
    "Total duration : 5:17:19  \n",
    "Loss duration : 3:58:50  \n",
    "Remaining duration : 1:18:29  \n",
    "Drop by percentage: 75.26  \n",
    "\n",
    "Total audio files : 4479  \n",
    "Files that would be drop: 3392    \n",
    "Remaining audio files : 1087  \n",
    "Drop by percentage: 75.73  \n",
    "**************************************************\n",
    "Non hindi tokes : ['!', '\"', '&', \"'\", ',', '-', '.', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '।', '‘', '’', '“', '”']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Loss of audio data for total dataset:\n",
      "**************************************************\n",
      "Total duration : 12:17:54\n",
      "Loss duration : 9:32:13\n",
      "Remaining duration : 2:45:40\n",
      "Drop by percentage: 77.55\n",
      "\n",
      "Total audio files : 9707\n",
      "Files that would be drop: 7637\n",
      "Remaining audio files : 2070\n",
      "Drop by percentage: 78.68\n"
     ]
    }
   ],
   "source": [
    "get_total_stats(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Dataset\n",
    "**************************************************\n",
    "Loss of audio data for total dataset:\n",
    "**************************************************\n",
    "Total duration : 12:17:54  \n",
    "Loss duration : 9:35:38  \n",
    "Remaining duration : 2:42:15  \n",
    "Drop by percentage: 78.01  \n",
    "\n",
    "Total audio files : 9707  \n",
    "Files that would be drop: 7680  \n",
    "Remaining audio files : 2027  \n",
    "Drop by percentage: 79.12  \n",
    "\n",
    "**************************************************\n",
    "Loss of audio data for total dataset After Decomposing Nuktas:\n",
    "**************************************************\n",
    "Total duration : 12:17:54  \n",
    "Loss duration : 9:32:13  \n",
    "Remaining duration : 2:45:40  \n",
    "Drop by percentage: 77.55  \n",
    "\n",
    "Total audio files : 9707  \n",
    "Files that would be drop: 7637  \n",
    "Remaining audio files : 2070  \n",
    "Drop by percentage: 78.68  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
