{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from pathlib import Path\n",
    "import plotly.graph_objects as px\n",
    "from utils.transcription_utils import get_transcription_info,get_stats,get_total_stats\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n",
    "import tarfile\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path=Path(\"/media/dataset-harddisk/munikumar/utils/audio_utils/data/kathbath/normalize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir=Path(\"/media/dataset-harddisk/munikumar/hindi_dataset/kathbath/kathbath_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_path=Path(\"/media/dataset-harddisk/munikumar/hindi_dataset/kathbath/kathbath/extract\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_files(extraction_path):\n",
    "    for tar_file in dataset_dir.glob(\"*.tar\"):\n",
    "        start_time = time.time()\n",
    "        with tarfile.open(tar_file) as tar:\n",
    "            with tqdm(desc=f\"Extracting {tar_file.name} \") as progress_bar:\n",
    "                member = tar.next()\n",
    "                while member is not None:\n",
    "                    progress_bar.update(1)\n",
    "                    if member.name.startswith(\"kb_data_clean_m4a/hindi/\"):\n",
    "                        tar.extract(member, path=str(extraction_path))\n",
    "                    member = tar.next()\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        print(f\"{tar_file.name} extraction time: {execution_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting transcripts_n2w.tar : 10it [00:00, 47.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting transcripts_n2w.tar : 48it [00:00, 102.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transcripts_n2w.tar extraction time: 0.4792 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train_audio.tar : 828562it [55:52, 247.11it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_audio.tar extraction time: 3352.9722 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting testunk_audio.tar : 19672it [00:47, 412.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testunk_audio.tar extraction time: 48.0201 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting valid_audio.tar : 32176it [01:49, 292.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_audio.tar extraction time: 109.8961 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting testkn_audio.tar : 31740it [01:06, 479.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testkn_audio.tar extraction time: 66.2309 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extract_files(extract_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transcription(transcription_path):\n",
    "    transcriptions={}\n",
    "    with open(transcription_path, \"r\", encoding=\"utf-8\") as fp:\n",
    "        for transcription_data in fp.read().splitlines():\n",
    "            audio_file = transcription_path.parent.name+\"/audio/\"+transcription_data.split(\"\\t\")[0]\n",
    "            transcription = transcription_data.split(\"\\t\")[-1]\n",
    "            transcriptions[audio_file] = transcription\n",
    "    return transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path=extract_path/\"kb_data_clean_m4a\"/\"hindi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting audio info about : normalize - test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 4319/5059 [04:29<00:45, 16.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5059/5059 [05:15<00:00, 16.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Loss of audio data without transcription normalization:\n",
      "**************************************************\n",
      "Total duration : 8:1:8\n",
      "Loss duration : 0:0:41\n",
      "Remaining duration : 8:0:26\n",
      "Drop by percentage: 0.14\n",
      "\n",
      "Total audio files : 5059\n",
      "Files that would be drop: 6\n",
      "Remaining audio files : 5053\n",
      "Drop by percentage: 0.12\n",
      "**************************************************\n",
      "Non hindi tokes : ['ऍ', 'ऽ', '॓']\n"
     ]
    }
   ],
   "source": [
    "test_transcription_data=load_transcription(dataset_path/\"test\"/\"transcription_n2w.txt\")\n",
    "testk_transcription_data=load_transcription(dataset_path/\"test_known\"/\"transcription_n2w.txt\")\n",
    "test_transcription_data.update(testk_transcription_data)\n",
    "get_transcription_info(test_transcription_data,dataset_path,save_path,\"test\")\n",
    "get_stats(save_path/\"test_non_hindi_transcripts.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dataset\n",
    "**************************************************\n",
    "Loss of audio data without transcription normalization:\n",
    "**************************************************\n",
    "Total duration : 8:1:8  \n",
    "Loss duration : 0:0:41  \n",
    "Remaining duration : 8:0:26  \n",
    "Drop by percentage: 0.14  \n",
    "\n",
    "Total audio files : 5059  \n",
    "Files that would be drop: 6  \n",
    "Remaining audio files : 5053  \n",
    "Drop by percentage: 0.12  \n",
    "**************************************************\n",
    "Non hindi tokes : ['ऍ', 'ऽ', '॓']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting audio info about : normalize - dev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3229 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3229/3229 [03:20<00:00, 16.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Loss of audio data without transcription normalization:\n",
      "**************************************************\n",
      "Total duration : 5:0:33\n",
      "Loss duration : 0:0:14\n",
      "Remaining duration : 5:0:18\n",
      "Drop by percentage: 0.08\n",
      "\n",
      "Total audio files : 3229\n",
      "Files that would be drop: 2\n",
      "Remaining audio files : 3227\n",
      "Drop by percentage: 0.06\n",
      "**************************************************\n",
      "Non hindi tokes : ['ऍ', 'ॆ']\n"
     ]
    }
   ],
   "source": [
    "valid_transcription_data=load_transcription(dataset_path/\"valid\"/\"transcription_n2w.txt\")\n",
    "get_transcription_info(valid_transcription_data,dataset_path,save_path,\"dev\")\n",
    "get_stats(save_path/\"dev_non_hindi_transcripts.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev Dataset\n",
    "**************************************************\n",
    "Loss of audio data without transcription normalization:\n",
    "**************************************************\n",
    "Total duration : 5:0:33  \n",
    "Loss duration : 0:0:14  \n",
    "Remaining duration : 5:0:18  \n",
    "Drop by percentage: 0.08  \n",
    "\n",
    "Total audio files : 3229  \n",
    "Files that would be drop: 2  \n",
    "Remaining audio files : 3227  \n",
    "Drop by percentage: 0.06  \n",
    "**************************************************\n",
    "Non hindi tokes : ['ऍ', 'ॆ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting audio info about : normalize - train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93024/93024 [2:06:06<00:00, 12.29it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Loss of audio data without transcription normalization:\n",
      "**************************************************\n",
      "Total duration : 137:19:4\n",
      "Loss duration : 0:5:10\n",
      "Remaining duration : 137:13:54\n",
      "Drop by percentage: 0.06\n",
      "\n",
      "Total audio files : 93024\n",
      "Files that would be drop: 46\n",
      "Remaining audio files : 92978\n",
      "Drop by percentage: 0.05\n",
      "**************************************************\n",
      "Non hindi tokes : ['ऌ', 'ऍ', 'ऎ', 'ऺ', 'ॆ', 'ॊ', 'ॐ', '॓', 'ॠ', 'ॡ', 'ॢ', '॰']\n"
     ]
    }
   ],
   "source": [
    "train_transcription_data=load_transcription(dataset_path/\"train\"/\"transcription_n2w.txt\")\n",
    "get_transcription_info(train_transcription_data,dataset_path,save_path,\"train\")\n",
    "get_stats(save_path/\"train_non_hindi_transcripts.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Dataset\n",
    "**************************************************\n",
    "Loss of audio data without transcription normalization:\n",
    "**************************************************\n",
    "Total duration : 137:19:4  \n",
    "Loss duration : 0:5:10  \n",
    "Remaining duration : 137:13:54  \n",
    "Drop by percentage: 0.06  \n",
    "\n",
    "Total audio files : 93024  \n",
    "Files that would be drop: 46  \n",
    "Remaining audio files : 92978  \n",
    "Drop by percentage: 0.05  \n",
    "**************************************************\n",
    "Non hindi tokes : ['ऌ', 'ऍ', 'ऎ', 'ऺ', 'ॆ', 'ॊ', 'ॐ', '॓', 'ॠ', 'ॡ', 'ॢ', '॰']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Loss of audio data for total dataset:\n",
      "**************************************************\n",
      "Total duration : 150:20:45\n",
      "Loss duration : 0:6:6\n",
      "Remaining duration : 150:14:39\n",
      "Drop by percentage: 0.07\n",
      "\n",
      "Total audio files : 101312\n",
      "Files that would be drop: 54\n",
      "Remaining audio files : 101258\n",
      "Drop by percentage: 0.05\n"
     ]
    }
   ],
   "source": [
    "get_total_stats(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Dataset\n",
    "**************************************************\n",
    "Loss of audio data for total dataset:\n",
    "**************************************************\n",
    "Total duration : 150:20:45  \n",
    "Loss duration : 0:6:6  \n",
    "Remaining duration : 150:14:39  \n",
    "Drop by percentage: 0.07  \n",
    "\n",
    "Total audio files : 101312  \n",
    "Files that would be drop: 54  \n",
    "Remaining audio files : 101258  \n",
    "Drop by percentage: 0.05  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kathbath Clean\n",
    "test: 1929  \n",
    "train: 93024  \n",
    "valid: 3229  \n",
    "test_known: 3130  \n",
    "total: 1_01_312  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kathbath Hard\n",
    "test: 816  \n",
    "test_known: 3034  \n",
    "total: 3850"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
